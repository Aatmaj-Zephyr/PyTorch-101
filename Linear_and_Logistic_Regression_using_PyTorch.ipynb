{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear and Logistic Regression using PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smlra-kjsce/Pytorch-101/blob/main/Linear_and_Logistic_Regression_using_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR57VDRKjGLX"
      },
      "source": [
        "# Importing necessary libraries\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import numpy as np\r\n",
        "from sklearn import datasets\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlhK-cQqoWgU"
      },
      "source": [
        "# Linear Regression \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAansz0UrWOp"
      },
      "source": [
        "## Step 1 - Making Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgtwp-hyk9ZV"
      },
      "source": [
        "# Making random dataset from sklearn.datsets\r\n",
        "x_np , y_np = datasets.make_regression(n_samples=100,n_features=1,noise=10,random_state=1)\r\n",
        "\r\n",
        "# Since the x_np and y_np are in numpy array form, we convert them to pytorch tensor\r\n",
        "x = torch.from_numpy(x_np.astype(np.float32))\r\n",
        "y = torch.from_numpy(y_np.astype(np.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDG48t3Bu2iU",
        "outputId": "636267a6-32d3-4c3a-c429-b3b7a0cb0c84"
      },
      "source": [
        "# We try to see the shape of the s and y tensor so that they are of valid dimension.\r\n",
        "\r\n",
        "print(x.shape)\r\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 1])\n",
            "torch.Size([100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aZkp9umq3gE"
      },
      "source": [
        "We see that y is of shape [100] so we convert it to shape [100,1] so that we can easily feed it to the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddOeupRfvdID",
        "outputId": "f676a4e5-191b-418f-9df9-2a41177f2d05"
      },
      "source": [
        "# We convert y of hsape 100 to (100,1) and see the shape \r\n",
        "\r\n",
        "y = y.view(y.shape[0],1)\r\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDRGJlBMrb90"
      },
      "source": [
        "## Step 2 - Designing Model\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnlDpd-xvlR0",
        "outputId": "9995d270-feb0-4336-dd58-9afc2d2aa5dd"
      },
      "source": [
        "# We try to understand the input and output size and make a model out of it\r\n",
        "\r\n",
        "# the no of featrues that each data-point has becomes out input size as any input will have that many values. \r\n",
        "# Eg. if no. of features is 2, we will have input of the form (a,b)\r\n",
        "no_of_samples, no_of_features = x.shape\r\n",
        "input_size = no_of_features\r\n",
        "\r\n",
        "# The ouput size will be the shape of each of the given y.\r\n",
        "output_size = y.shape[1]\r\n",
        "\r\n",
        "print(\"Input size is \" + str(input_size))\r\n",
        "print(\"Output size is \" + str(output_size))\r\n",
        "\r\n",
        "# We construct a linear model with the given input and output sizes\r\n",
        "model = nn.Linear(input_size,output_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input size is 1\n",
            "Output size is 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H54WX2hso-d"
      },
      "source": [
        "## Step 3 - Defining loss and optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdqJAqhYwd6a"
      },
      "source": [
        "# Loss and Optimizer \r\n",
        "\r\n",
        "learning_rate = 0.01 \r\n",
        "epochs = 1000\r\n",
        "\r\n",
        "# We take the standard mean squared loss\r\n",
        "model_loss = nn.MSELoss()\r\n",
        "\r\n",
        "# We take the SGD (Stochastic Gradient Descent) \r\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4TfOtqCs53e"
      },
      "source": [
        "## Step 4 - Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S382rx0xxmQD",
        "outputId": "ab074f3c-4b6d-4873-af5a-7ba5b01ace02"
      },
      "source": [
        "# Here we take all the components together and put them in a training loop.\r\n",
        "\r\n",
        "for epoch in range(epochs):\r\n",
        "  # Forward pass\r\n",
        "  y_hat = model(x)\r\n",
        "  loss = model_loss(y_hat,y)\r\n",
        "\r\n",
        "  # Backward pass\r\n",
        "  loss.backward()\r\n",
        "\r\n",
        "  # Update weights\r\n",
        "  optimizer.step()\r\n",
        "  optimizer.zero_grad()\r\n",
        "\r\n",
        "  # Printing it at every 10 epochs\r\n",
        "  if (epoch%10 == 0):\r\n",
        "    print(\"Epoch \" + str(epoch))\r\n",
        "    print(\"Loss \" + str(loss.item()))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Loss 5270.48876953125\n",
            "Epoch 10\n",
            "Loss 3848.965087890625\n",
            "Epoch 20\n",
            "Loss 2819.220947265625\n",
            "Epoch 30\n",
            "Loss 2072.54833984375\n",
            "Epoch 40\n",
            "Loss 1530.6400146484375\n",
            "Epoch 50\n",
            "Loss 1137.0137939453125\n",
            "Epoch 60\n",
            "Loss 850.8743896484375\n",
            "Epoch 70\n",
            "Loss 642.7232666015625\n",
            "Epoch 80\n",
            "Loss 491.2056579589844\n",
            "Epoch 90\n",
            "Loss 380.8469543457031\n",
            "Epoch 100\n",
            "Loss 300.4223327636719\n",
            "Epoch 110\n",
            "Loss 241.7830810546875\n",
            "Epoch 120\n",
            "Loss 199.00839233398438\n",
            "Epoch 130\n",
            "Loss 167.79331970214844\n",
            "Epoch 140\n",
            "Loss 145.00518798828125\n",
            "Epoch 150\n",
            "Loss 128.36312866210938\n",
            "Epoch 160\n",
            "Loss 116.2055892944336\n",
            "Epoch 170\n",
            "Loss 107.32167053222656\n",
            "Epoch 180\n",
            "Loss 100.82832336425781\n",
            "Epoch 190\n",
            "Loss 96.0808334350586\n",
            "Epoch 200\n",
            "Loss 92.60924530029297\n",
            "Epoch 210\n",
            "Loss 90.070068359375\n",
            "Epoch 220\n",
            "Loss 88.21258544921875\n",
            "Epoch 230\n",
            "Loss 86.85357666015625\n",
            "Epoch 240\n",
            "Loss 85.85906219482422\n",
            "Epoch 250\n",
            "Loss 85.13121032714844\n",
            "Epoch 260\n",
            "Loss 84.59845733642578\n",
            "Epoch 270\n",
            "Loss 84.20848846435547\n",
            "Epoch 280\n",
            "Loss 83.92294311523438\n",
            "Epoch 290\n",
            "Loss 83.71387481689453\n",
            "Epoch 300\n",
            "Loss 83.5608139038086\n",
            "Epoch 310\n",
            "Loss 83.44872283935547\n",
            "Epoch 320\n",
            "Loss 83.36663818359375\n",
            "Epoch 330\n",
            "Loss 83.30653381347656\n",
            "Epoch 340\n",
            "Loss 83.26251220703125\n",
            "Epoch 350\n",
            "Loss 83.23023223876953\n",
            "Epoch 360\n",
            "Loss 83.20661926269531\n",
            "Epoch 370\n",
            "Loss 83.18931579589844\n",
            "Epoch 380\n",
            "Loss 83.17664337158203\n",
            "Epoch 390\n",
            "Loss 83.16734313964844\n",
            "Epoch 400\n",
            "Loss 83.16053771972656\n",
            "Epoch 410\n",
            "Loss 83.15554809570312\n",
            "Epoch 420\n",
            "Loss 83.15190124511719\n",
            "Epoch 430\n",
            "Loss 83.14920806884766\n",
            "Epoch 440\n",
            "Loss 83.14725494384766\n",
            "Epoch 450\n",
            "Loss 83.14582061767578\n",
            "Epoch 460\n",
            "Loss 83.144775390625\n",
            "Epoch 470\n",
            "Loss 83.14400482177734\n",
            "Epoch 480\n",
            "Loss 83.14342498779297\n",
            "Epoch 490\n",
            "Loss 83.14302825927734\n",
            "Epoch 500\n",
            "Loss 83.1427230834961\n",
            "Epoch 510\n",
            "Loss 83.14250183105469\n",
            "Epoch 520\n",
            "Loss 83.142333984375\n",
            "Epoch 530\n",
            "Loss 83.14222717285156\n",
            "Epoch 540\n",
            "Loss 83.14212036132812\n",
            "Epoch 550\n",
            "Loss 83.1420669555664\n",
            "Epoch 560\n",
            "Loss 83.14202117919922\n",
            "Epoch 570\n",
            "Loss 83.1419906616211\n",
            "Epoch 580\n",
            "Loss 83.14196014404297\n",
            "Epoch 590\n",
            "Loss 83.14193725585938\n",
            "Epoch 600\n",
            "Loss 83.14192199707031\n",
            "Epoch 610\n",
            "Loss 83.14192199707031\n",
            "Epoch 620\n",
            "Loss 83.14190673828125\n",
            "Epoch 630\n",
            "Loss 83.14190673828125\n",
            "Epoch 640\n",
            "Loss 83.14189147949219\n",
            "Epoch 650\n",
            "Loss 83.14189147949219\n",
            "Epoch 660\n",
            "Loss 83.14189147949219\n",
            "Epoch 670\n",
            "Loss 83.14189147949219\n",
            "Epoch 680\n",
            "Loss 83.14189147949219\n",
            "Epoch 690\n",
            "Loss 83.14189147949219\n",
            "Epoch 700\n",
            "Loss 83.14189147949219\n",
            "Epoch 710\n",
            "Loss 83.14188385009766\n",
            "Epoch 720\n",
            "Loss 83.14189147949219\n",
            "Epoch 730\n",
            "Loss 83.14188385009766\n",
            "Epoch 740\n",
            "Loss 83.14189147949219\n",
            "Epoch 750\n",
            "Loss 83.14189147949219\n",
            "Epoch 760\n",
            "Loss 83.14189147949219\n",
            "Epoch 770\n",
            "Loss 83.14189147949219\n",
            "Epoch 780\n",
            "Loss 83.14188385009766\n",
            "Epoch 790\n",
            "Loss 83.14188385009766\n",
            "Epoch 800\n",
            "Loss 83.14189147949219\n",
            "Epoch 810\n",
            "Loss 83.14189147949219\n",
            "Epoch 820\n",
            "Loss 83.14189147949219\n",
            "Epoch 830\n",
            "Loss 83.14189147949219\n",
            "Epoch 840\n",
            "Loss 83.14189147949219\n",
            "Epoch 850\n",
            "Loss 83.14188385009766\n",
            "Epoch 860\n",
            "Loss 83.14188385009766\n",
            "Epoch 870\n",
            "Loss 83.14188385009766\n",
            "Epoch 880\n",
            "Loss 83.14189147949219\n",
            "Epoch 890\n",
            "Loss 83.14189147949219\n",
            "Epoch 900\n",
            "Loss 83.14189147949219\n",
            "Epoch 910\n",
            "Loss 83.14188385009766\n",
            "Epoch 920\n",
            "Loss 83.14189147949219\n",
            "Epoch 930\n",
            "Loss 83.14189147949219\n",
            "Epoch 940\n",
            "Loss 83.14189147949219\n",
            "Epoch 950\n",
            "Loss 83.14189147949219\n",
            "Epoch 960\n",
            "Loss 83.14189147949219\n",
            "Epoch 970\n",
            "Loss 83.14189147949219\n",
            "Epoch 980\n",
            "Loss 83.14189147949219\n",
            "Epoch 990\n",
            "Loss 83.14189147949219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9z9R8yqtSGJ"
      },
      "source": [
        "## Step 5 - Plot the graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ne71GSJoyyty",
        "outputId": "7b9a9a39-07f5-4161-fb1e-21c30b441260"
      },
      "source": [
        "# We first unwrap the predictions into a array named y_predicted\r\n",
        "y_predicted = model(x).detach().numpy()\r\n",
        "\r\n",
        "# We plot the original points\r\n",
        "plt.scatter(x_np,y_np,color=\"red\")\r\n",
        "\r\n",
        "# We plot the predictions \r\n",
        "plt.plot(x_np,y_predicted,color=\"blue\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN9THn8CwiHw"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHQ-vqpMsW1M"
      },
      "source": [
        "## Step 1 - Data Pre-processing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt687BC8zRLt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "188103e8-6fbb-413c-efd2-dec2f4f69b58"
      },
      "source": [
        "data = datasets.load_wine()\r\n",
        "\r\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
            "        1.065e+03],\n",
            "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
            "        1.050e+03],\n",
            "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
            "        1.185e+03],\n",
            "       ...,\n",
            "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
            "        8.350e+02],\n",
            "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
            "        8.400e+02],\n",
            "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
            "        5.600e+02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2]), 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'), 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n', 'feature_names': ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeulQ6wsnLJO",
        "outputId": "d89c55a9-4765-4e99-81df-845af0329404"
      },
      "source": [
        "# We try to understand the size of out dataset\r\n",
        "\r\n",
        "# We first load the data and target\r\n",
        "x,y = data.data, data.target\r\n",
        "\r\n",
        "# We find the no. of features and data-points\r\n",
        "no_of_samples, no_of_features = x.shape\r\n",
        "print(x.shape)\r\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(178, 13)\n",
            "(178,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z71ssHfSoDgD"
      },
      "source": [
        "We can see that there are 178 datapoints having 13 features each. Since y is of zero dimesnions, we rehshape it to (178,1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoqYvIgUq6TL",
        "outputId": "c9aa4c6f-4d34-4f64-bf38-1c08a3efc9fb"
      },
      "source": [
        "y = y.reshape(y.shape[0],1)\r\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(178, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSBUzolAP8Kf"
      },
      "source": [
        "We see that our dataset contains 3 different values of 'y', 0,1 and 2. This will create a problem as logistic regression works well with only binary classification. So, we remove the data points having class '1' and rename the class '2' as class '1'  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66uDYVQbcmM1",
        "outputId": "1269350d-099a-4512-bde9-376a14a6e8cc"
      },
      "source": [
        "# We create an empty list consisting of all the indices that need to be deleted, i.e. all indices having y value as 1\r\n",
        "to_be_deleted = []\r\n",
        "\r\n",
        "# In the for loop, we append the indices having y=1 to the above list 'to_be_deleted' and replce those with y=2 as y=1\r\n",
        "for i in range (len(y)):\r\n",
        "  if y[i]==1:\r\n",
        "    to_be_deleted.append(i)\r\n",
        "  if y[i]==2:\r\n",
        "    y[i]=1\r\n",
        "\r\n",
        "# We delete the indices present in to_be_deleted from x and y using np.delete\r\n",
        "# Note that axis=0 means rowwise deletion and axis=1 means column wise\r\n",
        "x = np.delete(x,to_be_deleted,axis=0)\r\n",
        "y = np.delete(y,to_be_deleted,axis=0)\r\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6qZdUDmuRPn",
        "outputId": "658e5ad7-3d34-4da1-d0d2-e8e79974dab9"
      },
      "source": [
        "print(y.shape)\r\n",
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(107, 1)\n",
            "(107, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6Sdz1yEnstQ",
        "outputId": "46fa8765-9fd8-48ce-d450-6ee2a5fee125"
      },
      "source": [
        "# We split the dataset into training and testing with the help of sklearn library\r\n",
        "\r\n",
        "# Note: Do not change the order of x_train,x_test,t_train,y_test as the function returns it in that order itself\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.1)\r\n",
        "\r\n",
        "print(x_train.shape)\r\n",
        "print(x_test.shape)\r\n",
        "print(y_train.shape)\r\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(96, 13)\n",
            "(11, 13)\n",
            "(96, 1)\n",
            "(11, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMp1i7BCqIX2"
      },
      "source": [
        "Since we are dealing with logistic regression, it is recommened to scale our data. We use standard scaler which will scale the data such that the mean of the data points is zero and the standard deviation is one. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IY8sOcPpfwl"
      },
      "source": [
        "sc = StandardScaler()\r\n",
        "x_train = sc.fit_transform(x_train)\r\n",
        "x_test = sc.fit_transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up2Qd5fzre_j",
        "outputId": "f4e51eef-f504-4469-a0f9-effe2d8c90af"
      },
      "source": [
        "# Having completed the preprocessing, we convert the numpy arrays to torch tensors so that we can use pytorch models. \r\n",
        "\r\n",
        "x_train = torch.from_numpy(x_train.astype(np.float32))\r\n",
        "x_test = torch.from_numpy(x_test.astype(np.float32))\r\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\r\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\r\n",
        "\r\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([11, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zCKX-9zsb0F"
      },
      "source": [
        "## Step 2 - Model\r\n",
        "\r\n",
        "Logistic Regression is essentially Linear regression with a sigmoid layer in it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJmdt-V4xCkp"
      },
      "source": [
        "Before diving in t the model, lets understand the __ init __ and self used exensively in pytorch models. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VoL850FwEc8",
        "outputId": "50b9406c-4ec1-494a-9524-b373cecfbffe"
      },
      "source": [
        "# We define a class named smlra and the __init__ function in it.  \r\n",
        "class smlra(object):\r\n",
        "  x = 100\r\n",
        "  def __init__(self):\r\n",
        "    self.x = 200\r\n",
        "\r\n",
        "# We import the class variables directly without initializing the class\r\n",
        "print(smlra.x)\r\n",
        "\r\n",
        "# When the object of the class is created i.e., here A is object and smlra is the class, then __init__ gets automatically called\r\n",
        "# __init__ is similar to class constructors in other object oriented programming languages\r\n",
        "A = smlra()\r\n",
        "print(A.x)\r\n",
        "\r\n",
        "# self is a hidden parameter which is passed evrytime the methods of the object are called.\r\n",
        "# In other programming languages, self is automatically passed, while in python, we have to declare it. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94532jSfsS9C"
      },
      "source": [
        "# We define our logistic regression class here\r\n",
        "\r\n",
        "class LogisticRegression(nn.Module): \r\n",
        "\r\n",
        "  # __init__ method of our LogisticRegression class is the simple linear regression layer \r\n",
        "  def __init__(self,no_of_input_features):\r\n",
        "    super(LogisticRegression, self).__init__()\r\n",
        "    self.linear = nn.Linear(no_of_input_features,1)              #This is because the output size is 1 (essentially between 0 and 1 as it is Logistic)\r\n",
        "  \r\n",
        "  # The forward method of our LogisticRegression class is built on the top of __init__ and is essentailly applies sigmoid layer on the linear layer\r\n",
        "  def forward(self,x):\r\n",
        "    y_predicted = torch.sigmoid(self.linear(x))\r\n",
        "    return y_predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BYFPCVl0G-j"
      },
      "source": [
        "model = LogisticRegression(no_of_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9H3V2rAD-w_"
      },
      "source": [
        "## Step 3 - Optimizer and Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4EuP_dKEFGe"
      },
      "source": [
        "Since it is a logistic regression, we take the binary cross-entropy loss for back-propagation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6ejogio0Qpp"
      },
      "source": [
        "# We first define the learning rate and the number of epochs\r\n",
        "learning_rate = 0.01\r\n",
        "epochs = 100\r\n",
        "\r\n",
        "# We then define the loss and the optimizer function\r\n",
        "loss = nn.BCELoss()\r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c59Czt8Eu1g"
      },
      "source": [
        "## Step 4 - Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GGn_EvREuHk",
        "outputId": "62a93051-c1c0-4eef-ad4a-3e0f3af853fb"
      },
      "source": [
        "for epoch in range(epochs):\r\n",
        "\r\n",
        "  # Forward pass\r\n",
        "  y_predicted = model(x_train)\r\n",
        "\r\n",
        "  # Backward pass\r\n",
        "  l = loss(y_predicted,y_train)\r\n",
        "  l.backward()\r\n",
        "\r\n",
        "  # Weights updated\r\n",
        "  optimizer.step()\r\n",
        "  optimizer.zero_grad()\r\n",
        "\r\n",
        "  if (epoch%10==0):\r\n",
        "    print(l)\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.6294, grad_fn=<BinaryCrossEntropyBackward>)\n",
            "tensor(0.5163, grad_fn=<BinaryCrossEntropyBackward>)\n",
            "tensor(0.4333, grad_fn=<BinaryCrossEntropyBackward>)\n",
            "tensor(0.3711, grad_fn=<BinaryCrossEntropyBackward>)\n",
            "tensor(0.3235, grad_fn=<BinaryCrossEntropyBackward>)\n",
            "tensor(0.2863, grad_fn=<BinaryCrossEntropyBackward>)\n",
            "tensor(0.2565, grad_fn=<BinaryCrossEntropyBackward>)\n",
            "tensor(0.2323, grad_fn=<BinaryCrossEntropyBackward>)\n",
            "tensor(0.2123, grad_fn=<BinaryCrossEntropyBackward>)\n",
            "tensor(0.1955, grad_fn=<BinaryCrossEntropyBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr5HlrWYHafK"
      },
      "source": [
        "## Step 5 - Test and Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jCW8kgjHibD",
        "outputId": "af54aee8-ce9f-47b1-a610-0999dbe708e6"
      },
      "source": [
        "# We predict the x_test things and since the sigmoid function gives a vale between 0 and 1, we round it off to get the desired classes\r\n",
        "with torch.no_grad():\r\n",
        "  y_pred = model(x_test)\r\n",
        "  y_predicted_classes = y_pred.round()\r\n",
        "\r\n",
        "# We print the actual classes and the predicted classes and see that the accuracy is 100% (due to small dataset)\r\n",
        "print(y_test)\r\n",
        "print(y_predicted_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]])\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO-jcKSQPDI0",
        "outputId": "015259b1-ebe3-45d2-b481-a73ef0feb3f2"
      },
      "source": [
        "# We print the confusion matrix.\r\n",
        "# In confusion matrix, the values along the diagonal are correctly predicted and others are wrongly predicted, which in our case is 0.\r\n",
        "print(confusion_matrix(y_test,y_predicted_classes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6 0]\n",
            " [0 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}